## 一次看日志踩的坑

### 故障现象

应用告警，产生大量org.mybatis.spring.MyBatisSystemException异常，其他应用调用该应用的dubbo服务都超时失败，产生com.alibaba.dubbo.rpc.RpcException，没有提供者的告警

### 处理过程
（按时间轴）
2019-07-25 10:35:37

测试同事开始上线应用（部署两台），发布ip133的机器成功

10:35:53

开始上线ip11的机器

10:37:00

我观察到cat上有大量告警，上线应用出现大量org.mybatis.spring.MyBatisSystemException异常，以为是有慢查询

10:38:00

与其他平台开发和DBA沟通后，发现无慢查询，这时发现其他服务出现的告警只有com.alibaba.dubbo.rpc.RpcException
原因是没有提供者，Exception com.alibaba.dubbo.rpc.RpcException: No provider available from registry x.x.x.105:2181 for service com.xx.xx.api.service.base.AddressConfigService:1.0.0 on consumer x.x.x.175 use dubbo version 2.x.x, may be providers disabled or not registered 

10:40:00

和经理等人沟通后，让测试执行回滚

10:41:56

开始回滚133这台机，检查健康检查页，发现恢复正常

10:45:02

两台机回滚完成，cat也不再告警，解决完毕



### 排查

和同事一起排查问题，发现告警只有133才产生，11的机器并没有任何告警

排查catalina.out日志，133是正常起来了的，并且一直有在刷日志

看日志发现11在上线启动的时候，没有成功连接到kafka，正在尝试重连（此时已经被我们回滚），意思是，此时所有的流量流进133的机器。

在36分这个时间点，发现同事在处理线上问题，正在使用vim查日志，此时的日志应该已经有六七百M（中午看到是800M），同时观察cat上的system info

![image-20190728105309396](/Users/pengdi/Library/Application Support/typora-user-images/image-20190728105340540.png)

发现cpu负载特别高，猜测是由于虚拟机被vim占用过多资源，造成程序性能下降，sql这种io操作将会变得很慢很慢甚至是阻塞，造成上线应用的获取不到数据库连接告警，而其他应用调用的dubbo服务，一旦需要dao，就会阻塞住

后续未改动代码重新上线，并未出现该问题

上线后，cat没有出现告警，至此，流程结束。

### 原因分析

如上所述，应该是由于系统资源匮乏，CPU负载过高，导致DAO这种IO操作会阻塞，11这台机又正在发布，并且发布完后，kafka连接不上，应用没有起来，所以产生大量没有提供者的告警。

以下是我对133这台机的一些猜测：

（1）发生了死锁

先看看死锁的四个条件

产生死锁的四个必要条件：

（1） 互斥条件：一个资源每次只能被一个进程使用。
（2） 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
（3） 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。
（4） 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

回到上述的场景，主要关注两个进程，一个是vim，一个是在跑的java程序。vim进程试图打开一个几百M的文件，读入内存，执行搜索命令，此时占据了CPU和内存。java程序则因为11的发布，所有流量流进该机器。

第一，需要一个互斥的资源，在这里，内存可能会是这样一个互斥资源。

第二，vim和java程序都会持有内存这种资源，并且可能需要更多的内存，因此占有并不放弃。

第三，进程获取的内存资源，是通过操作系统的内存调度，这里会涉及到虚存和实际物理内存，猜测是vim读取大容量的txt文件，并且执行搜索，导致短时间发生大量的缺页、抢占大量的物理内存。

第四，这个就比较抽象了，相当于是进程A在等进程B释放内存，进程B也在等进程A释放内存。vim继续读取，可能还继续发生缺页，触发内存调度，而另一方面程序的正常运行，也是需要内存资源的。

那么一来，死锁的四个必要条件就满足了，重点是在内存，因为CPU资源虽然也紧张，但是还是能得到一些时间分片的。发生死锁后，应用程序的运行也必然受到影响，不过现在还没办法证明告警是因为这个原因。

（2）CPU100%，没有空闲内存的时候，I/O操作还能正常进行吗？（个人更偏向于这个原因）

首先贴出应用的jvm内存参数 -Xms3120m -Xmx3120m  -Xss256k -XX:MetaspaceSize=256m -XX:NewRatio=2

垃圾收集器参数 -XX:+UseConcMarkSweepGC  -XX:+UseParNewGC  -XX:+UseCMSCompactAtFullCollection

再贴一张cat的133机器的gc情况，可以看到新生代垃圾回收的时间突增，这可能跟获取不到CPU时间片有关。

![image-20190728115700341](/Users/pengdi/Library/Application Support/typora-user-images/image-20190728115700341.png)

看看使用的垃圾收集器：

#### UseParNewGC

并发串行收集器，它是工作在新生代的垃圾收集器，它只是将串行收集器多线程化，除了这个并没有太多创新之处，而且它们共用了相当多的代码。它与串行收集器一样，也是独占式收集器，在收集过程中，应用程序会全部暂停。但它却是许多运行在Server模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关但很重要的原因是，除了Serial收集器外，目前只有它能与CMS收集器配合工作。

这个垃圾收集器是需要暂停应用程序的，而收集的时长又这么久，必然会影响到程序的运行效率，这是应用大量dao操作阻塞的原因之一。
